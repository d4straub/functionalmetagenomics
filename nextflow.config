params {
  max_memory = 1992.GB
  max_cpus = 128
  max_time = 168.h
}

singularity {
  enabled = true
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core Nextflow base config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    A 'blank slate' config file, appropriate for general use on most high performance
    compute environments. Assumes that all software is installed and available on
    the PATH. Runs in `local` mode - all jobs will be run on the logged in environment.
----------------------------------------------------------------------------------------
*/

process {

    cpus   = { check_max( 1    * task.attempt, 'cpus'   ) }
    memory = { check_max( 6.GB * task.attempt, 'memory' ) }
    time   = { check_max( 4.h  * task.attempt, 'time'   ) }

    errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
    maxRetries    = 3
    maxErrors     = '-1'

    // Process-specific resource requirements
    // NOTE - Please try and re-use the labels below as much as possible.
    //        These labels are used and recognised by default in DSL2 files hosted on nf-core/modules.
    //        If possible, it would be nice to keep the same label naming convention when
    //        adding in your local modules too.
    // See https://www.nextflow.io/docs/latest/config.html#config-process-selectors
    withLabel:process_single {
        cpus   = { check_max( 1                  , 'cpus'    ) }
        memory = { check_max( 6.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 4.h  * task.attempt, 'time'    ) }
    }
    withLabel:process_low {
        cpus   = { check_max( 2     * task.attempt, 'cpus'    ) }
        memory = { check_max( 12.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 6.h   * task.attempt, 'time'    ) }
    }
    withLabel:process_medium {
        cpus   = { check_max( 6     * task.attempt, 'cpus'    ) }
        memory = { check_max( 42.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 12.h   * task.attempt, 'time'   ) }
    }
    withLabel:process_high {
        cpus   = { check_max( 20    * task.attempt, 'cpus'    ) }
        memory = { check_max( 120.GB * task.attempt, 'memory' ) }
        time   = { check_max( 36.h  * task.attempt, 'time'    ) }
    }
    withLabel:process_long {
        time   = { check_max( 48.h  * task.attempt, 'time'    ) }
    }
    withLabel:single_cpu {
        cpus   = { check_max( 1                  , 'cpus'    ) }
    }
    withLabel:process_high_memory {
        memory = { check_max( 200.GB * task.attempt, 'memory' ) }
    }
    withLabel:error_ignore {
        errorStrategy = 'ignore'
    }
    withLabel:error_retry {
        errorStrategy = 'retry'
        maxRetries    = 3
    }
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core modules config file "modules.config"
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Define settings for each process
----------------------------------------------------------------------------------------
*/


params.publish_dir_mode = 'copy'
params.multiqc_title = false

process {

    publishDir = [
        path: { "${params.outdir}/${task.process.tokenize(':')[-1].tokenize('_')[0].toLowerCase()}" },
        mode: params.publish_dir_mode,
        enabled: false
    ]

    withName: FASTQC {
        ext.args = '--quiet'
        publishDir = [
            path: { "${params.outdir}/fastqc" },
            mode: params.publish_dir_mode,
            pattern: "*.html"
        ]
    }

    withName: MULTIQC {
        ext.args   = params.multiqc_title ? "--title \"$params.multiqc_title\"" : ''
        publishDir = [
            path: { "${params.outdir}/multiqc" },
            mode: params.publish_dir_mode,
            saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
        ]
    }

    withName: KNEADDATA {
        ext.args = ''
        publishDir = [
            path: { "${params.outdir}/kneaddata/log" },
            mode: params.publish_dir_mode,
            pattern: "*.log"
        ]
    }

    withName: KNEADDATA_SUMMARY {
        publishDir = [
            path: { "${params.outdir}/kneaddata" },
            mode: params.publish_dir_mode,
            saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
        ]
    }

    withName: METAPHLAN_METAPHLAN {
        publishDir = [
            path: { "${params.outdir}/metaphlan/per_sample" },
            mode: params.publish_dir_mode,
            saveAs: { filename -> filename.equals('versions.yml') ? null : filename },
            enabled: false
        ]
    }

    withName: METAPHLAN_MERGEMETAPHLANTABLES {
        publishDir = [
            path: { "${params.outdir}/metaphlan" },
            mode: params.publish_dir_mode,
            saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
        ]
    }

    withName: HUMANN_HUMANN {
        ext.args = '--search-mode uniref90 --remove-temp-output'
        publishDir = [
            path: { "${params.outdir}/humann/log" },
            mode: params.publish_dir_mode,
            pattern: "*.log"
        ]
    }

    withName: HUMANN_JOIN {
        publishDir = [
            [
                path: { "${params.outdir}/humann/log" },
                mode: params.publish_dir_mode,
                pattern: "*.log"
            ],
            [
                path: { "${params.outdir}/humann/0_joined_raw" },
                mode: params.publish_dir_mode,
                pattern: "*.tsv.gz"
            ]
        ]
    }

    withName: HUMANN_RENORM {
        ext.args = ''
        publishDir = [
            path: { "${params.outdir}/humann/1_renormed" },
            mode: params.publish_dir_mode,
            pattern: "*.tsv.gz"
        ]
    }

    withName: HUMANN_REGROUP {
        ext.args = ''
        publishDir = [
            path: { "${params.outdir}/humann/2_regrouped" },
            mode: params.publish_dir_mode,
            pattern: "*.tsv.gz"
        ]
    }

    withName: HUMANN_RENAME {
        ext.args = ''
        publishDir = [
            path: { "${params.outdir}/humann/3_renamed" },
            mode: params.publish_dir_mode,
            pattern: "*.tsv.gz"
        ]
    }

    withName: HUMANN_SPLITSTARTIFIEDTABLE {
        ext.args = ''
        publishDir = [
            path: { "${params.outdir}/humann/4_final" },
            mode: params.publish_dir_mode,
            saveAs: { filename -> filename.equals('versions.yml') || filename.endsWith('.log') ? null : filename }
        ]
    }

}